# 数据库性能优化方案

## 问题分析

**目标负载**：100 个并发用户同时查询股票数据和下单

### 1. 性能瓶颈识别

#### 1.1 读取场景（高频）
- K线数据查询：每个用户切换股票/周期时触发
- 实时价格查询：每个用户持续轮询最新价格
- 持仓查询：每次交易前后查询
- **预估 QPS**：100 用户 × 10 次/分钟 = **17 QPS（读）**

#### 1.2 写入场景（中频）
- K线数据写入：10 只股票 × 1 分钟 = **0.17 QPS（写）**
- 交易下单：100 用户 × 1 次/分钟 = **1.67 QPS（写）**

#### 1.3 性能要求
- **查询响应**：< 100ms (P95)
- **写入延迟**：< 50ms
- **并发支持**：100+ 连接

---

## 2. 数据库架构优化

### 2.1 技术选型

#### SQLite vs PostgreSQL 对比

| 特性 | SQLite | PostgreSQL | 推荐 |
|-----|--------|------------|------|
| 并发读 | ⚠️ 支持但受限 | ✅ 优秀 | PostgreSQL |
| 并发写 | ❌ 单线程写入 | ✅ MVCC 多版本 | PostgreSQL |
| 连接池 | ❌ 不支持 | ✅ 支持 | PostgreSQL |
| 索引优化 | ✅ 基础支持 | ✅ 丰富索引类型 | PostgreSQL |
| 分区表 | ❌ 不支持 | ✅ 原生支持 | PostgreSQL |
| 部署复杂度 | ✅ 零配置 | ⚠️ 需要安装 | - |

**结论**：
- **开发/测试阶段**：SQLite（快速启动）
- **生产环境**：PostgreSQL（性能和并发）

### 2.2 数据表优化设计

#### 2.2.1 K线数据表（优化版）

```sql
-- 使用 PostgreSQL

-- 1. 主表：按日期分区
CREATE TABLE market_klines (
    id BIGSERIAL,
    symbol VARCHAR(20) NOT NULL,
    interval VARCHAR(10) NOT NULL,
    time BIGINT NOT NULL,                    -- Unix 时间戳（秒）
    open NUMERIC(10, 2) NOT NULL,
    high NUMERIC(10, 2) NOT NULL,
    low NUMERIC(10, 2) NOT NULL,
    close NUMERIC(10, 2) NOT NULL,
    volume BIGINT NOT NULL,
    turnover NUMERIC(20, 2),

    PRIMARY KEY (symbol, interval, time)
) PARTITION BY RANGE (time);

-- 2. 创建分区（按月分区，减少查询扫描范围）
CREATE TABLE market_klines_2025_01 PARTITION OF market_klines
    FOR VALUES FROM (1704067200) TO (1706745600);  -- 2025-01

CREATE TABLE market_klines_2025_02 PARTITION OF market_klines
    FOR VALUES FROM (1706745600) TO (1709251200);  -- 2025-02

-- ... 自动化脚本创建未来分区

-- 3. 核心索引（覆盖索引，避免回表）
CREATE INDEX idx_symbol_interval_time ON market_klines (symbol, interval, time DESC)
    INCLUDE (open, high, low, close, volume);

-- 4. 最新价格快速查询索引
CREATE INDEX idx_latest_price ON market_klines (symbol, interval, time DESC)
    WHERE interval = '1m';

-- 5. 统计信息（加速聚合查询）
CREATE STATISTICS klines_stats ON symbol, interval, time FROM market_klines;
```

**性能提升**：
- ✅ 分区表减少扫描范围（**10x 提升**）
- ✅ 覆盖索引避免回表（**5x 提升**）
- ✅ 统计信息优化查询计划（**2x 提升**）

#### 2.2.2 实时价格缓存表

```sql
-- 单独的实时价格表（热数据，高频查询）
CREATE TABLE stock_realtime_price (
    symbol VARCHAR(20) PRIMARY KEY,
    current_price NUMERIC(10, 2) NOT NULL,
    prev_close NUMERIC(10, 2) NOT NULL,
    change_percent NUMERIC(6, 2),
    high_today NUMERIC(10, 2),
    low_today NUMERIC(10, 2),
    volume_today BIGINT,
    last_update BIGINT NOT NULL,              -- Unix 时间戳

    -- 索引
    INDEX idx_last_update (last_update)
);

-- 内存表优化（PostgreSQL 不支持，使用 unlogged 表）
CREATE UNLOGGED TABLE stock_realtime_price_fast AS
    SELECT * FROM stock_realtime_price;
```

**优势**：
- ✅ 单行查询，**< 1ms**
- ✅ 无需扫描 K 线历史数据
- ✅ 减少 JOIN 查询

### 2.3 连接池配置

```python
# backend/database.py

from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

# PostgreSQL 连接池
engine = create_engine(
    'postgresql://user:password@localhost/happystock',

    # 连接池配置
    poolclass=QueuePool,
    pool_size=20,              # 常驻连接数
    max_overflow=30,           # 额外连接数（峰值）
    pool_timeout=30,           # 获取连接超时
    pool_recycle=3600,         # 连接回收时间（1小时）
    pool_pre_ping=True,        # 连接健康检查

    # 性能优化
    echo=False,                # 关闭 SQL 日志（生产环境）
    isolation_level='READ COMMITTED',
)

# 异步连接池（可选）
from sqlalchemy.ext.asyncio import create_async_engine

async_engine = create_async_engine(
    'postgresql+asyncpg://user:password@localhost/happystock',
    pool_size=20,
    max_overflow=30,
)
```

---

## 3. 查询优化策略

### 3.1 K线数据查询（最常见）

#### 3.1.1 查询场景

```python
# 用户场景：查询最近 200 根 K 线
GET /api/klines?symbol=SH600000&interval=5m&limit=200
```

#### 3.1.2 优化前（慢查询）

```sql
-- ❌ 全表扫描，性能差
SELECT time, open, high, low, close, volume
FROM market_klines
WHERE symbol = 'SH600000' AND interval = '5m'
ORDER BY time DESC
LIMIT 200;

-- 执行计划：Seq Scan (cost=0..10000)
```

#### 3.1.3 优化后（快速查询）

```sql
-- ✅ 使用覆盖索引 + 分区裁剪
SELECT time, open, high, low, close, volume
FROM market_klines
WHERE symbol = 'SH600000'
  AND interval = '5m'
  AND time >= (EXTRACT(EPOCH FROM NOW()) - 86400 * 7)::BIGINT  -- 限制 7 天内
ORDER BY time DESC
LIMIT 200;

-- 执行计划：Index Only Scan (cost=0..50)
```

**性能对比**：
- 优化前：**~500ms**
- 优化后：**~10ms**（50x 提升）

### 3.2 批量查询优化

```python
# ❌ N+1 查询问题
for symbol in ['SH600000', 'SH600036', 'SH600519']:
    klines = db.query("""
        SELECT * FROM market_klines
        WHERE symbol = ? AND interval = '1m'
        LIMIT 200
    """, symbol)

# ✅ 批量查询
klines = db.query("""
    SELECT * FROM market_klines
    WHERE symbol IN ('SH600000', 'SH600036', 'SH600519')
      AND interval = '1m'
      AND time >= (EXTRACT(EPOCH FROM NOW()) - 3600)::BIGINT
    ORDER BY symbol, time DESC
""")

# 在应用层按 symbol 分组
klines_by_symbol = {}
for row in klines:
    if row['symbol'] not in klines_by_symbol:
        klines_by_symbol[row['symbol']] = []
    klines_by_symbol[row['symbol']].append(row)
```

### 3.3 实时价格查询

```python
# ✅ 单查询，极快
current_prices = db.query("""
    SELECT symbol, current_price, change_percent, last_update
    FROM stock_realtime_price
    WHERE symbol IN (?, ?, ?, ...)
""", symbols)

# 响应时间：< 5ms
```

---

## 4. 写入优化策略

### 4.1 批量写入 K 线数据

```python
# ❌ 逐条插入（慢）
for stock in stocks:
    for minute in range(120):
        db.execute("""
            INSERT INTO market_klines (symbol, interval, time, ...)
            VALUES (?, ?, ?, ...)
        """, stock['symbol'], '1m', timestamp, ...)

# 执行时间：10 只股票 × 120 分钟 = 1200 次插入 = ~12 秒

# ✅ 批量插入（快）
values = []
for stock in stocks:
    for minute in range(120):
        values.append((
            stock['symbol'], '1m', timestamp,
            kline['open'], kline['high'], kline['low'], kline['close'], kline['volume']
        ))

db.executemany("""
    INSERT INTO market_klines (symbol, interval, time, open, high, low, close, volume)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    ON CONFLICT (symbol, interval, time) DO UPDATE
    SET close = EXCLUDED.close, high = GREATEST(high, EXCLUDED.high), ...
""", values)

# 执行时间：1200 条数据 = ~200ms（60x 提升）
```

### 4.2 异步写入（进一步优化）

```python
import asyncio
from sqlalchemy.ext.asyncio import AsyncSession

async def batch_insert_klines(session: AsyncSession, klines: List[dict]):
    """异步批量插入"""
    stmt = insert(MarketKline).values(klines).on_conflict_do_update(...)
    await session.execute(stmt)
    await session.commit()

# 在守护进程中使用
async def generate_minute_data():
    klines = []
    for stock in stocks:
        kline = generate_next_price(...)
        klines.append(kline)

    # 异步写入，不阻塞
    asyncio.create_task(batch_insert_klines(session, klines))
```

### 4.3 使用消息队列缓冲

```python
# 架构优化：数据生成器 → Redis 队列 → 写入进程

# 1. 数据生成器（生产者）
import redis
r = redis.Redis()

def generate_minute_data():
    for stock in stocks:
        kline = generate_next_price(...)
        r.lpush('kline_queue', json.dumps(kline))

# 2. 数据库写入进程（消费者）
def kline_writer():
    while True:
        # 批量获取 100 条数据
        klines = []
        for _ in range(100):
            data = r.brpop('kline_queue', timeout=1)
            if data:
                klines.append(json.loads(data[1]))

        if klines:
            batch_insert_klines(klines)
```

**优势**：
- ✅ 解耦生成和写入
- ✅ 削峰填谷
- ✅ 高可用（Redis 持久化）

---

## 5. 缓存策略

### 5.1 应用层缓存（Redis）

```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_klines_cached(symbol: str, interval: str, limit: int = 200):
    """带缓存的 K 线查询"""

    # 1. 尝试从 Redis 获取
    cache_key = f"klines:{symbol}:{interval}:{limit}"
    cached = redis_client.get(cache_key)

    if cached:
        return json.loads(cached)

    # 2. 从数据库查询
    klines = db.query("""
        SELECT time, open, high, low, close, volume
        FROM market_klines
        WHERE symbol = ? AND interval = ?
        ORDER BY time DESC
        LIMIT ?
    """, symbol, interval, limit)

    # 3. 写入 Redis（TTL = 60 秒）
    redis_client.setex(cache_key, 60, json.dumps(klines))

    return klines
```

### 5.2 缓存失效策略

```python
def update_kline(symbol: str, interval: str, kline: dict):
    """更新 K 线时同步更新缓存"""

    # 1. 写入数据库
    db.execute("""
        INSERT INTO market_klines (...)
        VALUES (...)
        ON CONFLICT DO UPDATE ...
    """, ...)

    # 2. 删除相关缓存
    cache_keys = [
        f"klines:{symbol}:{interval}:*",
        f"latest_price:{symbol}",
    ]
    for pattern in cache_keys:
        for key in redis_client.scan_iter(pattern):
            redis_client.delete(key)
```

### 5.3 缓存预热

```python
def preheat_cache():
    """预热热门股票缓存"""
    hot_stocks = ['SH600000', 'SH600036', 'SH600519']
    intervals = ['1m', '5m', '15m', '1d']

    for symbol in hot_stocks:
        for interval in intervals:
            get_klines_cached(symbol, interval, 200)

    print("缓存预热完成")
```

---

## 6. 监控和调优

### 6.1 性能监控指标

```python
# 使用 Prometheus + Grafana

from prometheus_client import Counter, Histogram, Gauge

# 1. 查询性能
query_duration = Histogram(
    'db_query_duration_seconds',
    'Database query duration',
    ['query_type']
)

# 2. 连接池状态
pool_size = Gauge(
    'db_pool_size',
    'Database connection pool size'
)

# 3. 查询 QPS
query_qps = Counter(
    'db_query_total',
    'Total database queries',
    ['query_type', 'status']
)

# 使用示例
with query_duration.labels('get_klines').time():
    klines = get_klines(symbol, interval)
    query_qps.labels('get_klines', 'success').inc()
```

### 6.2 慢查询日志

```sql
-- PostgreSQL 配置
ALTER SYSTEM SET log_min_duration_statement = 100;  -- 记录 > 100ms 的查询
ALTER SYSTEM SET log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d ';

-- 查看慢查询
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
WHERE mean_time > 100
ORDER BY total_time DESC
LIMIT 20;
```

### 6.3 数据库调优

```sql
-- PostgreSQL 配置优化（适合 8GB RAM 服务器）

-- 1. 内存配置
ALTER SYSTEM SET shared_buffers = '2GB';           -- 共享缓冲区
ALTER SYSTEM SET effective_cache_size = '6GB';     -- 操作系统缓存
ALTER SYSTEM SET work_mem = '16MB';                 -- 排序/JOIN 内存
ALTER SYSTEM SET maintenance_work_mem = '512MB';    -- 维护操作内存

-- 2. 并发配置
ALTER SYSTEM SET max_connections = 200;             -- 最大连接数
ALTER SYSTEM SET max_worker_processes = 8;          -- 并行工作进程

-- 3. 查询优化
ALTER SYSTEM SET random_page_cost = 1.1;            -- SSD 优化
ALTER SYSTEM SET effective_io_concurrency = 200;    -- 并发 I/O

-- 4. 日志配置
ALTER SYSTEM SET log_statement = 'none';            -- 不记录所有语句
ALTER SYSTEM SET log_duration = off;                -- 不记录执行时间

-- 重启 PostgreSQL 生效
SELECT pg_reload_conf();
```

---

## 7. 压力测试

### 7.1 测试脚本

```python
# tests/load_test.py

import asyncio
import aiohttp
import time

async def query_klines(session, symbol, interval):
    """模拟用户查询"""
    async with session.get(
        f'http://localhost:8000/api/klines',
        params={'symbol': symbol, 'interval': interval, 'limit': 200}
    ) as resp:
        return await resp.json()

async def simulate_user(user_id):
    """模拟单个用户行为"""
    async with aiohttp.ClientSession() as session:
        symbols = ['SH600000', 'SH600036', 'SH600519']
        intervals = ['1m', '5m', '15m', '1d']

        for _ in range(10):  # 每个用户查询 10 次
            symbol = random.choice(symbols)
            interval = random.choice(intervals)

            start = time.time()
            await query_klines(session, symbol, interval)
            duration = time.time() - start

            print(f"User {user_id}: {duration:.3f}s")
            await asyncio.sleep(random.uniform(1, 5))

async def load_test(num_users=100):
    """压力测试：100 个并发用户"""
    tasks = [simulate_user(i) for i in range(num_users)]
    await asyncio.gather(*tasks)

# 运行测试
asyncio.run(load_test(100))
```

### 7.2 性能目标

| 指标 | 目标 | 当前 | 状态 |
|-----|------|------|------|
| 查询响应时间 (P95) | < 100ms | - | ⏳ 待测 |
| 查询响应时间 (P99) | < 200ms | - | ⏳ 待测 |
| 并发连接数 | 100+ | - | ⏳ 待测 |
| QPS（读） | 20+ | - | ⏳ 待测 |
| QPS（写） | 5+ | - | ⏳ 待测 |
| 数据库 CPU | < 50% | - | ⏳ 待测 |
| 内存使用 | < 4GB | - | ⏳ 待测 |

---

## 8. 实施计划

### 阶段 1：数据库迁移（1 天）
- [x] 设计优化后的表结构
- [ ] 创建 PostgreSQL 数据库
- [ ] 编写迁移脚本
- [ ] 创建索引和分区

### 阶段 2：连接池配置（0.5 天）
- [ ] 配置 SQLAlchemy 连接池
- [ ] 测试连接池性能
- [ ] 调整连接池参数

### 阶段 3：查询优化（1 天）
- [ ] 重写 K 线查询 API
- [ ] 添加 Redis 缓存
- [ ] 批量查询优化

### 阶段 4：写入优化（1 天）
- [ ] 批量写入实现
- [ ] 异步写入优化
- [ ] Redis 队列集成（可选）

### 阶段 5：压力测试（1 天）
- [ ] 编写测试脚本
- [ ] 执行压力测试
- [ ] 性能调优
- [ ] 验证性能目标

---

*文档版本：v1.0*
*最后更新：2025-10-27*
